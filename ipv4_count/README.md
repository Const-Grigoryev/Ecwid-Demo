IPv4 Count
==========

Дан простой текстовый файл с IPv4 адресами. Одна строка – один адрес, примерно так:

```
145.67.23.4
8.34.5.23
89.54.3.124
89.54.3.124
3.45.71.5
...
```

Файл в размере не ограничен и может занимать десятки и сотни гигабайт.

Необходимо посчитать количество __уникальных адресов__ в этом файле, затратив как можно меньше памяти и времени.
Существует "наивный" алгоритм решения данной задачи (читаем строка за строкой, кладем строки в HashSet), желательно
чтобы ваша реализация была лучше этого простого, наивного алгоритма.

Немного деталей:
- По всем вопросам смело писать на join@ecwid.com
- Использовать можно только возможности стандартной библиотеки Java/Kotlin
- Писать нужно на Java (версия 11 и выше) или Kotlin.
- В задании должен быть рабочий метод main(), это должно быть готовое приложение, а не просто библиотека
- Сделанное задание необходимо разместить на GitHub

---
Прежде чем отправить задание, имеет смысл проверить его вот на этом [файле](https://ecwid-vgv-storage.s3.eu-central-1.amazonaws.com/ip_addresses.zip).
Внимание – файл весит около 20Gb, а распаковывается приблизительно в 120Gb.


Заметки по реализации
---------------------

1. Программу можно использовать как в режиме пользовательского приложения (класс `IPv4CountApp`), так и в режиме
   библиотеки (класс `IPv4Count`). Класс `IPv4CountApp` сам по себе занимается только соблюдением протокола ОС,
   а всю реальную работу делегирует движку `IPv4Count`.
   
2. Общий интерфейс приложения соответствует таковому для большинства Unix-утилит:
     - входом по умолчанию является стандартный поток ввода;
     - результат печатается в стандартный поток вывода;
     - ошибки, буде они случатся, валятся в `STDERR`;
     - поддерживаются разные коды завершения: 0 — всё прошло относительно гладко, -1 — случилась фатальная ошибка.

3. Сердцем алгоритма является класс `BitScale`. Логически он представляет собой массив булевых значений, каждое из
   которых соответствует одному возможному адресу из пространства IPv4: «истина» означает, что адрес присутствует
   в просмотренной части списка, «ложь» — что отсутствует. Физически эти значения упакованы в «слова» по 64 штуки.
   Поскольку объём адресного пространства IPv4 составляет 2<sup>32</sup>, весь битовый массив имеет размер
   2<sup>29</sup> байт, или 512 Мб.
   
4. Хотя 512 Мб вполне влезает в память современных машин, дизайн кода допускает замену битового массива какой-нибудь
   более экономной структурой данных, например, [фильтром Блума][Bloom_filter]. При этом удастся получить выигрыш
   в потреблении памяти (и, вероятно, быстродействии — благодаря уменьшению количества cache misses), пожертвовав
   точностью подсчёта.

5. Класс `BitScale` можно расширить, добавив методы для его представления в виде стандартного списка `List<Boolean>`
   или множества `Set<Long>`. Для данной задачи это не нужно, так как потребует большого количества дополнительной
   работы. Однако такой задел на будущее оставлен намеренно: эта структура данных довольно универсальна и хорошо
   подходит для повторного использования.

6. Другой важный компонент — парсер IP-адресов `IPv4Parser`. Он выполнен на [конечном автомате][Finite_state_machine],
   построенном вручную — это традиционное, хорошо зарекомендовавшее себя решение для такого рода задач. Альтернативами
   могли бы быть:
     - использование ANTLR или аналогичного инструмента для генерации кода;
     - библиотека [комбинаторных парсеров][Parser_combinator];
     - [рекурсивный парсер][Recursive_descent_parser];
     - спагетти-парсер.
     
7. Так как по условию утилита должна спокойно переваривать файлы размером 120 Гб (то есть около 8 млрд. строк),
   создавать временные объекты на каждой строке *крайне* нежелательно: это слишком сильно нагрузит сборщик мусора.
   Поэтому парсер написан в несколько старомодном C-подобном стиле, с изменяемыми переменными, управляющими флагами,
   колбэками и большим `switch`-ем внутри. В том числе, я сознательно избегал использования `String` и метода
   `Reader.readLine`, который для каждой строчки входного файла создаёт по объекту, а то и по два: собственно `String`
   и массив символов в нём. В итоге ни единого `new` в основном цикле парсера! (*N.B.* К сожалению, я не могу ручаться
   за другой библиотечный код. Вполне вероятно, что где-то в недрах UTF-кодека временные объекты всё жё создаются, но
   написание собственного декодера для Юникода явно выходит за рамки задачи. В любом случае я рассчитываю, что
   стандартный декодер уже отлично оптимизирован, поскольку работать с текстовыми файлами приходится буквально
   в каждом приложении. *UPD.* Нет, этот расчёт был катастрофически неверный).
   
8. Строго говоря, перфекционистская цель в $O(1)$ аллокаций достигнута не была: один временный объект создаётся каждый
   раз при заполнении буфера в `LineNumberReader` (в методе `StreamDecoder.implRead`). Поэтому, с учётом типичного
   размера задачи, буфер был увеличен до 1 млн. символов. В результате файл размером 120 Гб порождает всего 120 тыс.
   временных объектов — вполне достойный результат. При этом сохраняется ещё ресурс для оптимизации: в крайнем случае,
   можно пожертвовать универсальностью, выкинуть все эти устаревшие `Reader`-ы с `InputStream`-ами и читать прямо из
   `FileChannel`.
   

Что дальше?
-----------

Как можно улучшить код или дополнить функционал утилиты:

[ ] Поддержка разных кодировок. Со стороны пользователя это будет выглядеть как необязательный параметр командной
    строки: `-e cp1251`, например.

[ ] Кодировку по умолчанию сменить на более легковесную однобайтовую самоделку, в которой были бы только цифры, точки
    и переводы строк. Потенциально это даст очень сильный буст производительности.
   
[ ] Прямое чтение из файла (или нескольких), а не из `STDIN`. Опять же, как параметры командной строки: `file1.txt
    file2.txt file3.txt`. Может быть, стоит замаппить файл в память, — вдруг это даст какой-то выигрыш в скорости?
    Последнее, конечно, нужно выяснять экспериментальным путём.

[ ] Расширенный синтаксис. Разрешить комментарии и пробельные символы, ~~поддержать IPv6~~ (хотя нет, для этого
    придётся переделывать `BitScale`). Короче, тут есть где разгуляться фантазии.

[ ] Более детальные сообщения об ошибках. Сейчас, по сути, их всего два вида:
      - **Invalid octet value** — переполнение октета, семантическая ошибка;
      - **Unexpected character** — любая синтаксическая ошибка. 

[ ] Редизайн интерфейса `IPv4Parser`. Имеющаяся сигнатура `parseNextLine` не отражает тот факт, что концептуально
    результат парсинга является типом-суммой:
    ```haskell
    data ParseResult = Address Int | Error String | BlankLine | EndOfFile
    ```
    Объединив `ParseResult` и `IPv4Builder` в один *visitor*, можно будет исправить этот недочёт, а заодно и избавиться
    от поля `lastError`, которое тоже выглядит как-то... по-WinAPI-шному стрёмно. (Дороже ли визитор по сравнению
    с одиночной лямбдой? Вроде бы нет.)

[ ] Альтернативное предложение по предыдущему пункту: пусть `parseNextLine` возвращает `long`. В такое расширение
    влезает и код результата (т.е. `ParseResult`), и прочитанное значение адреса. Также можно получить небольшое
    ускорение, избавившись от вызова колбэка. С другой стороны, придётся отказаться от гарантий, предоставляемых
    системой типов, и пожертвовать читаемостью кода.

[ ] Отображать номер строчки в сообщении об ошибке. При этом нужно будет пофиксить баг, связанный с переполнением
    счётчика строк в `LineNumberReader`.

[ ] Рефакторинг конечного автомата. Пока что смысл `State`-ов остаётся немного туманным и неочевидно, почему
    выполняются инварианты.

[ ] Рефакторинг бенчмарков. В первой версии иерархия классов получилась очень запутанной, имеет смысл группировать
    бенчмарки по типу входных данных, а не по use case.


Бенчмаркинг
-----------

Бенчмаркинг в данной задаче преследует две цели: оценить производительность программы на файлах большого объёма
(около 120 ГБ) и выявить места для дальнейшей оптимизации. Соответственно, бенчмарки разделены на две большие группы:
«интегральные» измеряют время работы программы в целом, «компонентные» — её отдельных частей.

Тестирование проводилось на машине со следующей конфигурацией:

  - Intel i7-4500U CPU (4 cores @ 1.80 GHz);
  - 8 GB RAM (DDR3 1600 MHz);
  - 2 TB SATA-III SSD;
  - Microsoft Windows 10 + HotSpot JVM 17.0.11 (64-bit);
  - Ubuntu Linux 23.10.1 + OpenJDK 17.0.9-ea (64-bit).


### Интегральные бенчмарки

<details>
<summary>Сырые данные</summary>

#### Windows

    Benchmark                              (lines)  Mode  Cnt      Score     Error  Units
    ApplicationBenchmark.n00_generateOnly       1K    ss           0.444             s/op
    ApplicationBenchmark.n00_generateOnly      25K    ss           0.431             s/op
    ApplicationBenchmark.n00_generateOnly       1M    ss           1.274             s/op
    ApplicationBenchmark.n00_generateOnly      16M    ss          14.031             s/op
    ApplicationBenchmark.n01_liveInput          1K    ss           0.726             s/op
    ApplicationBenchmark.n01_liveInput         25K    ss           0.842             s/op
    ApplicationBenchmark.n01_liveInput          1M    ss           3.255             s/op
    ApplicationBenchmark.n01_liveInput         16M    ss          41.650             s/op
    ApplicationBenchmark.n02_fileInput          1K    ss           0.552             s/op
    ApplicationBenchmark.n02_fileInput         25K    ss           0.564             s/op
    ApplicationBenchmark.n02_fileInput          1M    ss           1.101             s/op
    ApplicationBenchmark.n02_fileInput         16M    ss           8.771             s/op
    EngineBenchmark.n00_generateOnly            1K    ss           0.016             s/op
    EngineBenchmark.n00_generateOnly           25K    ss           0.031             s/op
    EngineBenchmark.n00_generateOnly            1M    ss           0.098             s/op
    EngineBenchmark.n00_generateOnly           16M    ss           0.830             s/op
    EngineBenchmark.n01_liveInput               1K    ss           0.345             s/op
    EngineBenchmark.n01_liveInput              25K    ss           0.364             s/op
    EngineBenchmark.n01_liveInput               1M    ss           1.079             s/op
    EngineBenchmark.n01_liveInput              16M    ss           8.518             s/op
    EngineBenchmark.n02_fileInput               1K    ss           0.333             s/op
    EngineBenchmark.n02_fileInput              25K    ss           0.351             s/op
    EngineBenchmark.n02_fileInput               1M    ss           0.836             s/op
    EngineBenchmark.n02_fileInput              16M    ss           7.494             s/op
    LoadBenchmark.n01_measure_1k               N/A    ss   15      0.082 ±   0.002   s/op
    LoadBenchmark.n02_measure_25k              N/A    ss   10      0.102 ±   0.005   s/op
    LoadBenchmark.n03_measure_1m               N/A    ss    5      0.789 ±   0.076   s/op
    LoadBenchmark.n04_measure_16m              N/A    ss    3     11.422 ±   1.915   s/op
    LoadBenchmark.n05_measure_200m             N/A    ss         137.288             s/op
    LoadBenchmark.n06_measure_8b               N/A    ss        5470.897             s/op

#### Linux

    Benchmark                              (lines)  Mode  Cnt      Score     Error  Units
    ApplicationBenchmark.n00_generateOnly       1K    ss           0.431             s/op
    ApplicationBenchmark.n00_generateOnly      25K    ss           0.446             s/op
    ApplicationBenchmark.n00_generateOnly       1M    ss           1.372             s/op
    ApplicationBenchmark.n00_generateOnly      16M    ss          14.998             s/op
    ApplicationBenchmark.n01_liveInput          1K    ss           0.723             s/op
    ApplicationBenchmark.n01_liveInput         25K    ss           0.775             s/op
    ApplicationBenchmark.n01_liveInput          1M    ss           2.710             s/op
    ApplicationBenchmark.n01_liveInput         16M    ss          32.529             s/op
    ApplicationBenchmark.n02_fileInput          1K    ss           0.509             s/op
    ApplicationBenchmark.n02_fileInput         25K    ss           0.575             s/op
    ApplicationBenchmark.n02_fileInput          1M    ss           1.118             s/op
    ApplicationBenchmark.n02_fileInput         16M    ss           8.497             s/op
    EngineBenchmark.n00_generateOnly            1K    ss           0.021             s/op
    EngineBenchmark.n00_generateOnly           25K    ss           0.029             s/op
    EngineBenchmark.n00_generateOnly            1M    ss           0.127             s/op
    EngineBenchmark.n00_generateOnly           16M    ss           0.964             s/op
    EngineBenchmark.n01_liveInput               1K    ss           0.417             s/op
    EngineBenchmark.n01_liveInput              25K    ss           0.441             s/op
    EngineBenchmark.n01_liveInput               1M    ss           1.268             s/op
    EngineBenchmark.n01_liveInput              16M    ss          12.857             s/op
    EngineBenchmark.n02_fileInput               1K    ss           0.390             s/op
    EngineBenchmark.n02_fileInput              25K    ss           0.416             s/op
    EngineBenchmark.n02_fileInput               1M    ss           0.973             s/op
    EngineBenchmark.n02_fileInput              16M    ss           8.324             s/op
    LoadBenchmark.n01_measure_1k               N/A    ss   15      0.102 ±   0.004   s/op
    LoadBenchmark.n02_measure_25k              N/A    ss   10      0.124 ±   0.008   s/op
    LoadBenchmark.n03_measure_1m               N/A    ss    5      0.888 ±   0.078   s/op
    LoadBenchmark.n04_measure_16m              N/A    ss    3     12.474 ±   5.776   s/op
    LoadBenchmark.n05_measure_200m             N/A    ss         127.603             s/op
    LoadBenchmark.n06_measure_8b               N/A    ss        6038.040             s/op

</details>

Так как на моем ноутбуке нет свободных 120 ГБ, вместо физического файла пришлось использовать рандомный генератор,
но для сравнения я также взял несколько настоящих файлов меньшего размера (от 1 тыс. до 16 млн. строк, т.е. от 15 КБ
до 240 МБ). Я предполагал, что узким местом станет именно ввод-вывод, а генератор, запущенный в отдельном процессе,
будет выплёвывать строчки быстрее, чем основная программа (которую я далее буду называть просто _счётчиком_) будет
парсить их. Таким образом, использование генератора не должно было повлиять на результаты измерений. Однако эта моя
гипотеза не выдержала проверки. Соответствующие бенчмарки собраны в классе `ApplicationBenchmark`[^jmh-misuse]:

[^jmh-misuse]: Здесь генератор и счётчик запускаются в отдельных процессах с помощью `ProcessBuilder`. Понятно,
что JMH не предназначен для подобных сценариев, но здесь нам и не нужен точный результат, достаточно самых грубых
оценок.

  1. `n02_fileInput` измеряет производительность счётчика на реальных физических файлах. С файлом из 16 млн. адресов
     программа справляется примерно за 8 сек. На это значение будем ориентироваться.
  2. `n00_generatorOnly` запускает генератор и перенаправляет его вывод в */dev/null*. Даже в таком режиме генератор
     оказывается почти вдвое медленнее основной программы!
  3. `n01_liveInput` — генератор и счётчик, соединенные через пайп. Оказалось, что это не просто медленнее, чем
     генератор и счётчик по отдельности, а медленнее *в разы*. Интересно, кстати, что и в Linux, и в Windows картина
     с пайпами качественно одинаковая; возможно, я просто не умею их готовить.

С другой стороны, под контролем JMH в пределах одной виртуальной машины (и даже одного потока) генератор и счётчик
вместе показали гораздо более стабильный результат. По сути, здесь счётчик работал «в режиме библиотеки». Этот
сценарий оценивается бенчмарками из `EngineBenchmark`:

   1. `n00_generatorOnly` измеряет производительность генератора отдельно от счётчика. Видно, что она почти на порядок
      превосходит производительность счётчика, то есть вклад генератора в общее время работы пренебрежимо мал. Именно
      мы и добивались.   
   2. `n02_fileInput`, как и в прошлый раз, берёт в качестве входных данных реальный файл. Видно, что цифры времени
      работы в этом случае более-менее совпадает с теми, что были получены в режиме приложения. Следовательно,
      тестирование производительности в режиме библиотеки — вполне адекватная альтернатива бенчмаркингу всей программы
      целиком.
   3. `n01_liveInput` позволяет убедиться, что генератор и счётчик вместе дают предсказуемый результат. В режиме
      приложения, как мы помним, именно с этим были основные проблемы.

Наконец, `LoadBenchmark` измеряет производительность на по-настоящему больших входах. Концептуально это в точности
`EngineBenchmark.n01_liveInput`, просто вынесенный в отдельный класс для удобства. Цифры, полученные этим бенчмарком,
используются для проверки детальной модели (см. ниже).

Видно также, что производительность в Linux систематически отстаёт примерно на 10%. Вероятно, это связано с настройками
электропитания и общей загруженностью системы. В следующих версиях нужно будет постараться нивелировать эту разницу.


### Компонентные бенчмарки

<details>
<summary>Сырые данные</summary>

#### Windows

    Benchmark                  (dataset)  Mode  Cnt      Score     Error  Units
    BitScaleBenchmark.measure             avgt   12      0.008 ±   0.001  us/op
    InitBenchmark.measure            N/A  avgt   12  78373.175 ± 997.937  us/op
    ParserBenchmark.measure               avgt   12      0.080 ±   0.008  us/op
    ReaderBenchmark.measure               avgt   12      0.558 ±   0.003  us/op

#### Linux

    Benchmark                  (dataset)  Mode  Cnt      Score     Error  Units
    BitScaleBenchmark.measure             avgt   12      0.010 ±   0.001  us/op
    InitBenchmark.measure            N/A  avgt   12  92606.888 ± 500.351  us/op
    ParserBenchmark.measure               avgt   12      0.084 ±   0.001  us/op
    ReaderBenchmark.measure               avgt   12      0.635 ±   0.001  us/op

</details>

Общее время работы программы складывается из следующих вещей:

  - получение бинарных данных из источника (реального файла или генератора);
  - декодирование в текстовую форму;
  - парсинг IP-адресов;
  - учёт каждого адреса в структуре данных.

Каждая из этих величин пропорциональна объему входа. Кроме того, существует постоянная составляющая, связанная
с инициализацией всех компонентов.

Чтением данных из файла занимается операционная система, и она делает это очень быстро. Фактически, естественным
ограничением здесь выступают возможности железа, а не софта. Например, наиболее распространённые сейчас SSD на SATA 3
работают на скоростях около 500 МБ/с — для нас это 35 адресов в микросекунду, или 0.029 мкс на строчку. Как мы уже
выяснили, производительность Java-кода (более 0.5 мкс на строчку) и близко не подбирается к этим числам.

Остальные составляющие тестируются отдельными бенчмарками, с результатами которых можно ознакомиться выше (см. спойлер
в начале раздела). Выводы из них следующие:

  1. Время работы программы может быть оценено как 0.65 мкс на строчку, плюс 78 мс единоразово на инициализацию.
     В более привычных терминах это означает производительность **22 МБ/c**. Эта модель хорошо (с погрешностью
     не более 10%) согласуется с реальными данными. 
  2. Львиная доля времени — более 85% — уходит на декодирование Юникода. Следовательно, сохраняется **огромный**
     простор для оптимизации. Оставим его на следующую итерацию.

[Bloom_filter]: https://en.wikipedia.org/wiki/Bloom_filter
[Finite_state_machine]: https://en.wikipedia.org/wiki/Finite-state_machine
[Parser_combinator]: https://en.wikipedia.org/wiki/Parser_combinator
[Recursive_descent_parser]: https://en.wikipedia.org/wiki/Recursive_descent_parser