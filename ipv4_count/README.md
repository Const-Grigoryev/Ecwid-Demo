IPv4 Count
==========

Дан простой текстовый файл с IPv4 адресами. Одна строка – один адрес, примерно так:

```
145.67.23.4
8.34.5.23
89.54.3.124
89.54.3.124
3.45.71.5
...
```

Файл в размере не ограничен и может занимать десятки и сотни гигабайт.

Необходимо посчитать количество __уникальных адресов__ в этом файле, затратив как можно меньше памяти и времени.
Существует "наивный" алгоритм решения данной задачи (читаем строка за строкой, кладем строки в HashSet), желательно
чтобы ваша реализация была лучше этого простого, наивного алгоритма.

Немного деталей:
- По всем вопросам смело писать на join@ecwid.com
- Использовать можно только возможности стандартной библиотеки Java/Kotlin
- Писать нужно на Java (версия 11 и выше) или Kotlin.
- В задании должен быть рабочий метод main(), это должно быть готовое приложение, а не просто библиотека
- Сделанное задание необходимо разместить на GitHub

---
Прежде чем отправить задание, имеет смысл проверить его вот на этом [файле](https://ecwid-vgv-storage.s3.eu-central-1.amazonaws.com/ip_addresses.zip).
Внимание – файл весит около 20Gb, а распаковывается приблизительно в 120Gb.


Заметки по реализации
---------------------

1. Программу можно использовать как в режиме пользовательского приложения (класс `IPv4CountApp`), так и в режиме
   библиотеки (класс `IPv4Count`). Класс `IPv4CountApp` сам по себе занимается только соблюдением протокола ОС,
   а всю реальную работу делегирует движку `IPv4Count`.
   
2. Общий интерфейс приложения соответствует таковому для большинства Unix-утилит:
     - имя входного файла передаётся в командной строке, а если оно не указано, входом по умолчанию становится
       стандартный поток ввода;
     - результат печатается в стандартный поток вывода;
     - ошибки, буде они случатся, валятся в `STDERR`;
     - поддерживаются разные коды завершения: 0 — всё прошло относительно гладко, –1 — случилась фатальная ошибка,
       –2 указывает на некорректные значения параметров командной строки.

3. Программа работает в одном потоке, и это осознанное архитектурное решение. Теоретически, сама задача хорошо подходит
   для распараллеливания, но произвольный доступ к файлу, необходимый для этого, может быть медленнее последовательного
   в 2–10 раз (это зависит от модели установленного SSD, в моём случае, скорее, ближе ко второй цифре). Такое
   замедление сведёт на нет весь потенциальный выигрыш от распараллеливания. В целом, многопоточное решение возможно
   в рамках эксперимента, но вряд ли целесообразно.

4. Сердцем алгоритма является класс `BitScale`. Логически он представляет собой массив булевых значений, каждое из
   которых соответствует одному возможному адресу из пространства IPv4: «истина» означает, что адрес присутствует
   в просмотренной части списка, «ложь» — что отсутствует. Физически эти значения упакованы в «слова» по 64 штуки.
   Поскольку объём адресного пространства IPv4 составляет 2³², весь битовый массив имеет размер 2²⁹ байт, или 512 МБ.
   
5. Хотя 512 МБ вполне влезает в память современных машин, дизайн кода допускает замену битового массива какой-нибудь
   более экономной структурой данных, например, [фильтром Блума][Bloom_filter]. При этом удастся получить выигрыш
   в потреблении памяти (и, вероятно, быстродействии — благодаря уменьшению количества cache misses), пожертвовав
   точностью подсчёта.

6. Класс `BitScale` можно расширить, добавив методы для его представления в виде стандартного списка `List<Boolean>`
   или множества `Set<Long>`. Для данной задачи это не нужно, так как потребует большого количества дополнительной
   работы. Однако такой задел на будущее оставлен намеренно: эта структура данных довольно универсальна и хорошо
   подходит для повторного использования.

7. Другой важный компонент — парсер IP-адресов. Деталям его реализации посвящена [отдельная глава](#парсер-ip-адресов).
   Принципиально лишь то, что он выполнен на [конечном автомате][Finite_state_machine], построенном вручную — это
   традиционное, хорошо зарекомендовавшее себя решение для такого рода задач. Альтернативами могли бы быть:
     - использование ANTLR или аналогичного инструмента для генерации кода;
     - библиотека [комбинаторных парсеров][Parser_combinator];
     - [рекурсивный парсер][Recursive_descent_parser];
     - спагетти-парсер.
   
8. Для перекодирования бинарного входного потока в текст используется самодельный `LightweightInputStreamReader`.
   Он гораздо быстрее, чем стандартный `InputStreamReader`, за счёт отказа от поддержки разнообразных кодировок
   и возможности работы в многопоточном окружении. Он также не требует никаких дополнительных аллокаций при чтении
   (за исключением методов, читающих в массив, которыми я всё равно не пользуюсь). Единственная фича, которая в нём
   есть, — унификация различных символов разрыва строки, — сохранена ради преемственности с предыдущей версией,
   использовавшей `LineNumberReader`. 


### Парсер IP-адресов

#### Дизайн парсера: реализация

При разработке парсера основной акцент был сделан на скорость его работы. Такая расстановка приоритетов заставила
избегать высокоуровневых абстракций и чрезвычайно внимательно относиться к расходованию памяти. 

Так как по условию утилита должна спокойно переваривать файлы размером 120 ГБ (то есть около 8 млрд. строк),
создавать временные объекты в основном цикле программы было бы *крайне* нежелательно: даже один такой объект на строчку
слишком сильно нагрузил бы сборщик мусора. В частности, я сознательно отказался от стандартного `String`-а и очень
удобного в других обстоятельствах метода `Reader.readLine`. Ведь он при каждом вызове создаёт по объекту, а то и по два:
собственно `String` и массив символов в нём!

В итоге парсер пришлось писать в несколько старомодном C-подобном стиле, с изменяемыми переменными, управляющими
флагами, колбэками и большим `switch`-ем внутри. Поэтому в коде непросто разобраться с первого взгляда, даже
несмотря на подробные комментарии, что может затруднить его поддержку. Зато с точки зрения расхода памяти парсер
безупречен: в основном цикле моего кода нет ни единого `new`!

К сожалению, того же нельзя сказать про библиотечный код. Во-первых, стандартный `InputStreamReader` внутри себя
всё-таки создаёт один небольшой объект при каждом заполнении буфера. Во-вторых, он сам по себе довольно медленный
из-за необходимости переноса данных между разнотипными буферами. Для решения этой проблемы я просто написал свой
`LightweightInputStreamReader` минимальным набором методов.

Наиболее спорным местом остаётся взаимодействие парсера с `Reader`-ом. Парсер запрашивает символы по одному, что
означает, что резолвинг виртуального метода `Reader.read` и обновление состояния всей цепочки объектов, стоящих за
парсером, происходят *на каждом байте* входных данных. Не то чтобы это представляло какую-то проблему для современных
Java-машин, но раз уж начал заниматься микрооптимизациями, то становится сложно остановиться. Пока что я придерживаюсь
мнения, что универсальность и читаемость кода оправдывают жертву в 10–15% перформанса.


#### Дизайн парсера: интерфейс

Парсер был переосмыслен с момента прошлого релиза. Если там парсер — отдельный класс с не вполне понятным состоянием,
то сейчас парсер — это отдельный метод `parseLine`, подмешанный к `IPv4LineVisitor` (в Kotlin я бы сделал extension
method). Причем здесь visitor? Сейчас объясню.

В принципе, задача парсера состоит в классификации каждой строчки входного файла как корректной (содержащей валидный
IP-адрес), некорректной (содержащей синтаксическую ошибку или просто не имеющей отношения к делу текст) или просто
пустой. В функциональных языках для такого рода классификаций используют тип-сумму и pattern matching, в ООП —
наследование классов и [паттерн *visitor*][Visitor_pattern]. *Visitor* — это наш «pattern matching дома», причём
особенно его любят именно в контексте парсинга и разного прочего компиляторостроения, хотя область его применения
этим не ограничивается. С практической же точки зрения, visitor («посетитель») — просто объект, содержащий по методу
на каждый из вариантов, допустимых классификацией, а сам акт классификации («посещение») всегда сводится к вызову
одного (и только одного!) из этих методов.

Однако вопреки тому, что пишут в книжках, visitor-у совершенно необязательно работать с объектами из одной иерархии.
Вполне достаточно того, чтобы у них было какое-нибудь единое представление, которое можно анализировать; например,
в виде текстовой строки. Это как раз наш случай: метод `parseLine` считывает одну строчку, разбирает и классифицирует
её и вызывает, в зависимости от результата, один из методов-продолжений[^continuation] `address`, `mistake` или
`nothing`. Никакой промежуточный объект при этом создавать не требуется! (Помните про цель добиться нуля аллокаций
на строчку?)

[^continuation]: Ещё одно умное слово. *Visitor* — это пример техники под названием [continuation-passing style (CPS)][Continuation-passing_style],
когда функция (в нашём случае `parseLine`) не возвращаёт значение напрямую, а спрашивает вызывающую сторону, что та
собиралась делать с ним, и делает это сама. Вот это «что вы собираетесь делать с результатом» и называется
_продолжением_ (continuation). На самом деле, продолжение — это обычный колбэк, который просто передаётся в функцию
дополнительным параметром; отсюда, собственно, и название. У нас продолжений несколько, и передаются они через `this`,
но суть всё равно та же. Кстати, через CPS можно эмулировать и другие фичи, которых нет в вашем любимом языке: ленивые
вычисления, исключения, кортежи, корутины, даже монады. Более того, зачастую даже в языках, в которых эти фичи есть,
под капотом они именно так и работают!

С другой стороны, *visitor* достаточно гибок, чтобы при необходимости *можно* было создать объект, представляющий
строчку с адресом, любого вида. Это открывает возможности для переиспользования кода. Например, если нам потребуется
неизменяемое представление, можно реализовать интерфейс `IPv4LineVisitor` в фабрике или билдере. Даже никакие адаптеры
не нужны: методы-продолжения суть *в точности* фабричные методы или методы, конфигурирующие билдер (см. пример кода
в тесте [*VisitorTest.kt*](src/test/kotlin/dev/aspid812/ipv4_count/impl/VisitorTest.kt#L16)).
А в данном проекте используется изменяемое представление `MutableIPv4Line`: в нём продолжения являются обычными
setter-ами.

Пару слов о недостатках такой реализации. Пуристы могут обратить внимание, что у нас каждая строчка требует вызова
двух интерфейсных методов, и один из них почти наверняка не будет оптимизирован виртуальной машиной. Причём очевидно,
что в поставленной задаче можно обойтись и без этого. Что ж, действительно, я рассматривал альтернативный вариант
дизайна, в котором парсер упаковывал прочитанный адрес и код ошибки в один `long` и просто возвращал его `return`-ом.
Но мне так и не удалось получить от него статистически значимый прирост производительности, и я решил, что несколько
потенциально сэкономленных тактов процессора не стоят того, чтобы отказываться от универсальности решения и гарантий,
предоставляемых системой типов.


Что дальше?
-----------

Как можно улучшить код или дополнить функционал утилиты:

- [ ] Поддержка разных кодировок. Со стороны пользователя это будет выглядеть как необязательный параметр командной
  строки: `-e cp1251`, например.

- [X] Кодировку по умолчанию сменить на более легковесную однобайтовую самоделку, в которой были бы только цифры, точки
  и переводы строк. Потенциально, это может очень сильно забустить производительность. *UPD:* сделано в v1.1, ускорение
  декодера ×3.4, общее ускорение ×2.

- [ ] Полноценный интерфейс командной строки. Как минимум, опции `-h` и `-v` должны присутствовать в каждой утилите.

- [ ] Добавить возможность перечисления файлов по маске: `./foo/*.txt`.

- [ ] Ещё одна полезная опция: флажок, включающий fail-fast режим.

- [X] Прямое чтение из файла (или нескольких), а не из `STDIN`. Опять же, как параметры командной строки: `file1.txt
  file2.txt file3.txt`. **UPD:** сделано в v2.0.

- [X] Миграция на NIO. В ходе экспериментов выяснилось, что даже простое последовательное чтение из `FileChannel`
  в несколько раз превосходит по скорости `InputStream`. Придётся перекроить API (опять!), но такую возможность нельзя
  упускать. **UPD:** сделано в v2.0.

- [ ] После этого можно будет поэкспериментировать с более продвинутыми техниками: прямым маппингом файлов в память,
  параллельным чтением в несколько потоков, двойной буферизацией. Однако усилий это потребует колоссальных, а будет ли
  хоть какой-то практический выхлоп, неясно.

- [ ] Расширенный синтаксис. Разрешить комментарии и пробельные символы, ~~поддержать IPv6~~ (хотя нет, для этого
  придётся переделывать `BitScale`). Короче, тут есть где разгуляться фантазии.

- [ ] Более детальные сообщения об ошибках. Сейчас, по сути, их всего три (*UPD:* а было-то два — прогресс!):
    - **Invalid octet value** — переполнение октета, семантическая ошибка;
    - **Malformed address (too short)** — строчка содержит меньше четырёх октетов, синтаксическая ошибка;
    - **Unexpected character** — любая другая ошибка в синтаксисе.

- [X] Редизайн интерфейса `IPv4Parser`. Претензии к существующему дизайну и варианты их разрешения обсуждаются
  в [соответствующем разделе](#дизайн-парсера-интерфейс). *UPD:* сделано в v1.1.

- [ ] Отображать номер строчки в сообщении об ошибке.

- [X] Рефакторинг конечного автомата. Пока что смысл `State`-ов остаётся немного туманным, и неочевидно, почему
  выполняются инварианты. *UPD:* сделано в v1.1.

- [X] Рефакторинг бенчмарков. В первой версии иерархия классов получилась очень запутанной, имеет смысл группировать
  бенчмарки по типу входных данных, а не по use case.


Бенчмаркинг
-----------

Тестирование проводилось на машине со следующей конфигурацией:

  - Intel i7-4500U CPU (4 cores @ 1.80 GHz);
  - 8 GB RAM (DDR3 1600 MHz);
  - 2 TB SATA-III SSD;
  - Microsoft Windows 10 + HotSpot JVM 17.0.11 (64-bit);
  - Ubuntu Linux 23.10.1 + OpenJDK 17.0.9-ea (64-bit).

Для оценки быстродействия утилиты и отдельных её частей в различных режимах я написал несколько бенчмарков. Главный
из них называется `BI02_Performance` и измеряет общее время выполнения программы при чтении физического файла,
содержащего 500 млн. адресов[^dataset-excuses]. Согласно экспериментам, в Windows оно составляет 76–85 с (медиана
80 с). В более привычных терминах это означает производительность около **85 МБ/с**, или 160 нс на строчку.

[^dataset-excuses]: Технические ограничения не позволяют использовать для тестов файл, предложенный в условии —
у меня просто нет столько свободного места. Тем не менее и 500 млн. адресов (6.64 ГБ) вполне достаточно, чтобы оценить
общую производительность. Единственная проблема состоит в том, что на таких объёмах может быть заметно влияние кэша
файловой системы, поэтому для получения более реалистичных результатов бенчмарки не следует запускать несколько раз
подряд.


[Bloom_filter]: https://en.wikipedia.org/wiki/Bloom_filter
[Continuation-passing_style]: https://en.wikipedia.org/wiki/Continuation-passing_style
[Factory]: https://en.wikipedia.org/wiki/Factory_(object-oriented_programming)
[Finite_state_machine]: https://en.wikipedia.org/wiki/Finite-state_machine
[Parser_combinator]: https://en.wikipedia.org/wiki/Parser_combinator
[Recursive_descent_parser]: https://en.wikipedia.org/wiki/Recursive_descent_parser
[Visitor_pattern]: https://en.wikipedia.org/wiki/Visitor_pattern
